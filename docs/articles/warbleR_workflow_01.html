<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>
<center><font size="7"><b>warbleR: Import sound files and select signals</b></font></center> • warbleR</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="&lt;center&gt;&lt;font size=">
</head>
<body>
<b>warbleR: Import sound files and select signals</b>" /&gt;
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">warbleR</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.1.21</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Intro_to_warbleR.html">&lt;center&gt;&lt;font size="7"&gt;&lt;b&gt;Introduction to warbleR&lt;/b&gt;&lt;/font&gt;&lt;/center&gt;</a>
    </li>
    <li>
      <a href="../articles/warbleR_workflow_01.html">&lt;center&gt;&lt;font size="7"&gt;&lt;b&gt;warbleR&amp;#58; Import sound files and select signals&lt;/b&gt;&lt;/font&gt;&lt;/center&gt;</a>
    </li>
    <li>
      <a href="../articles/warbleR_workflow_02.html">&lt;center&gt;&lt;font size="7"&gt;&lt;b&gt;warbleR&amp;#58; Visual inspection and signal classification&lt;/b&gt;&lt;/font&gt;&lt;/center&gt;</a>
    </li>
    <li>
      <a href="../articles/warbleR_workflow_03.html">&lt;center&gt;&lt;font size="7"&gt;&lt;b&gt;warbleR&amp;#58; Acoustic (dis)similarity, coordinated singing and simulating songs&lt;/b&gt;&lt;/font&gt;&lt;/center&gt;</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1><center>
<font size="7"><b>warbleR: Import sound files and select signals</b></font>
</center></h1>
                        <h4 class="author"><center>
<a href="http://marceloarayasalas.weebly.com/">Marcelo Araya-Salas, PhD</a>
</center></h4>
                        <h4 class="author">
<center>
<a href="http://smith-vidaurre.com/">Grace Smith-Vidaurre</a>
</center>
</h4>
<p> </p>
            
            <h4 class="date"><center>
“2020-02-07”
</center></h4>
      
      
      <div class="hidden name"><code>warbleR_workflow_01.Rmd</code></div>

    </div>

    
    
<!-- <script> -->
<!--    $(document).ready(function() { -->
<!--      $head = $('#header'); -->
<!--      $head.prepend('<img src=\"logo.png\"/>') -->
<!--    }); -->
<!-- </script> -->
<!-- &nbsp;  -->
<center>
<img src="logo.png" alt="warbleR logo">
</center>
<p> </p>
<div id="bioacoustics-in-r-with-warbler" class="section level2">
<h2 class="hasAnchor">
<a href="#bioacoustics-in-r-with-warbler" class="anchor"></a>Bioacoustics in R with <code>warbleR</code>
</h2>
<p>Bioacoustics research encompasses a wide range of questions, study systems and methods, including the software used for analyses. The <code>warbleR</code> and <code>Rraven</code> packages leverage the flexibility of the <code>R</code> environment to offer a broad and accessible bioinformatics tool set. These packages fundamentally rely upon two types of data to perform bioacoustics analyses in R:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Sound files:</strong> Recordings in <em>wav</em> or <em>mp3</em> format, either from your own research or open-access databases like <em>xeno-canto</em></p></li>
<li><p><strong>Selection tables:</strong> Selection tables contain the temporal coordinates (start and end points) of selected acoustic signals within recordings</p></li>
</ol>
<div id="package-repositories" class="section level3">
<h3 class="hasAnchor">
<a href="#package-repositories" class="anchor"></a>Package repositories</h3>
<p>These packages are both available on <em>CRAN</em>: <a href="https://cran.r-project.org/package=warbleR"><code>warbleR</code></a>, <a href="https://cran.r-project.org/package=Rraven"><code>Rraven</code></a>, as well as on <em>GitHub</em>: <a href="https://github.com/maRce10/warbleR"><code>warbleR</code></a>, <a href="https://github.com/maRce10/Rraven"><code>Rraven</code></a>. The GitHub repository will always contain the latest functions and updates. You can also check out an article in <em>Methods in Ecology and Evolution</em> documenting the <code>warbleR</code> package <a href="#References"><sup>[1]</sup></a>.</p>
<p>We welcome all users to provide feedback, contribute updates or new functions and report bugs to warbleR’s GitHub repository.</p>
<p>Please note that <code>warbleR</code> and <code>Rraven</code> use functions from the <a href="https://cran.r-project.org/package=seewave"><code>seewave</code></a>, <a href="https://cran.r-project.org/package=monitoR"><code>monitoR</code></a>, <a href="https://cran.r-project.org/package=tuneR"><code>tuneR</code></a> and <a href="https://cran.r-project.org/package=dtw"><code>dtw</code></a> packages internally. <code>warbleR</code> and <code>Rraven</code> have been designed to make bioacoustics analyses more accessible to <code>R</code> users, and such analyses would not be possible without the tools provided by the packages above. These packages should be given credit when using <code>warbleR</code> and <code>Rraven</code> by including citations in publications as appropriate (e.g. <code><a href="https://rdrr.io/r/utils/citation.html">citation("seewave")</a></code>).</p>
</div>
<div id="parallel-processing-in-warbler" class="section level3">
<h3 class="hasAnchor">
<a href="#parallel-processing-in-warbler" class="anchor"></a>Parallel processing in <code>warbleR</code>
</h3>
<p>Parallel processing, or using multiple cores on your machine, can greatly speed up analyses. All iterative <code>warbleR</code> functions now have parallel processing for Linux, Mac and Windows operating systems. These functions also contain progress bars to visualize progress during normal or parallel processing. See <a href="#References"><sup>[1]</sup></a> for more details about improved running time using parallel processing.</p>
</div>
</div>
<div id="vignette-introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#vignette-introduction" class="anchor"></a><strong>Vignette introduction</strong>
</h2>
<p>Below we present a case study of microgeographic vocal variation in long-billed hermit hummingbirds, <em>Phaethornis longirostris</em>. Variation at small geographic scales has been already described in this species <a href="#References"><sup>[2]</sup></a>. Our goal is to search for visible differences in song structure within a site, and then determine whether underlying differences in acoustic parameters are representative of spectrographic distinctiveness. In this vignette, we will demonstrate how to:</p>
<ol style="list-style-type: decimal">
<li><p>Prepare for bioacoustics analyses by downloading <code>warbleR</code> and <code>Rraven</code></p></li>
<li><p>Use <code>Rraven</code> to import <em>Raven</em> selection tables for your own recordings</p></li>
<li><p>Obtain recordings from the open-access database <a href="http://www.xeno-canto.org/"><em>xeno-canto</em></a></p></li>
<li><p>Select signals using <code>warbleR</code> functions</p></li>
</ol>
<p>This vignette can be run without an advanced understanding of <code>R</code>, as long as you know how to run code in your console. However, knowing more about basic <code>R</code> coding would be very helpful to modify the code for your research questions.</p>
<p>For more details about function arguments, input or output, read the documentation for the function in question (e.g. <code><a href="../reference/querxc.html">?querxc</a></code>).  </p>
</div>
<div id="prepare-for-analyses" class="section level2">
<h2 class="hasAnchor">
<a href="#prepare-for-analyses" class="anchor"></a><strong>Prepare for analyses</strong>
</h2>
<div id="install-and-load-packages" class="section level3">
<h3 class="hasAnchor">
<a href="#install-and-load-packages" class="anchor"></a>Install and load packages</h3>
<p>First, we need to install and load <code>warbleR</code> and <code>Rraven</code>. You will need an <code>R</code> version ≥ 3.2.1 and <code>seewave</code> version ≥ 2.0.1. Also, users using <code>UNIX</code> machines (Linux or Mac operating systems), may need to install <code>fftw3</code>, <code>pkg-config</code> and <code>libsndfile</code> on their machines prior to installing <code>warbleR</code>. These external packages will need to be installed through a <code>UNIX</code> terminal. Installing these packages lies outside the scope of this vignette, but you can find more information on <em>Google</em>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### Install packages from CRAN
<span class="co"># Note that if you install from CRAN, then don't run the code to install from GitHub below, and vice versa</span>
<span class="kw"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span>(<span class="st">"warbleR"</span>)
<span class="kw"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span>(<span class="st">"Rraven"</span>)

### Alternatively, install warbleR and Rraven from GitHub repositories, which contain the latest updates
<span class="co"># Run this ONLY if devtools is not already installed</span>
<span class="kw"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span>(<span class="st">"devtools"</span>)

<span class="co"># Load devtools to access the install_github function</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(devtools)

<span class="co"># Install packages from GitHub</span>
<span class="co"># install_github("maRce10/warbleR")</span>
<span class="co"># install_github("maRce10/Rraven")</span>
<span class="co"># install_github("maRce10/NatureSounds")</span>

<span class="co"># Load warbleR and Rraven into your global environment</span>
X &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"warbleR"</span>, <span class="st">"Rraven"</span>)
<span class="kw"><a href="https://rdrr.io/r/base/invisible.html">invisible</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(X, library, <span class="dt">character.only =</span> <span class="ot">TRUE</span>))</code></pre></div>
<p>This vignette series will not always include all available <code>warbleR</code> functions, as existing functions are updated and new functions are added. To see all functions available in this package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The package must be loaded in your working environment</span>
<span class="kw"><a href="https://rdrr.io/r/base/ls.html">ls</a></span>(<span class="st">"package:warbleR"</span>)</code></pre></div>
<p> </p>
</div>
<div id="make-a-new-directory-and-set-your-working-directory" class="section level3">
<h3 class="hasAnchor">
<a href="#make-a-new-directory-and-set-your-working-directory" class="anchor"></a>Make a new directory and set your working directory</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create a new directory and set your working directory (assuming that you are in your /home/username directory)</span>
<span class="kw"><a href="https://rdrr.io/r/base/files2.html">dir.create</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/getwd.html">getwd</a></span>(),<span class="st">"warbleR_example"</span>))
<span class="kw"><a href="https://rdrr.io/r/base/getwd.html">setwd</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/getwd.html">getwd</a></span>(),<span class="st">"warbleR_example"</span>))

<span class="co"># Check your location</span>
<span class="kw"><a href="https://rdrr.io/r/base/getwd.html">getwd</a></span>()</code></pre></div>
<p> </p>
</div>
</div>
<div id="import-selection-tables" class="section level2">
<h2 class="hasAnchor">
<a href="#import-selection-tables" class="anchor"></a><strong>Import selection tables</strong>
</h2>
<p><code>Rraven</code> is an interface between <em>Raven</em> and <code>R</code> that allows you to import selection tables for your own recordings. This is very useful if you prefer to select signals in recordings outside of <code>R</code>. Once you have selection tables imported into <code>R</code> and the corresponding sound files in your working directory, you can move on to making spectrograms or performing analyses (see the next vignette in this series).</p>
<p>The sound files and selection tables loaded here correspond to male long-billed hermit hummingbird songs recorded at La Selva Biological Station in Costa Rica. Later, we will add to this data set by searching for more recordings on the <em>xeno-canto</em> open-access database.</p>
<p>Check out the <code>Rraven</code> package documentation for more functions and information (although you will need <em>Raven</em> or <em>Syrinx</em> installed on your computer for some functions).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load Raven example selection tables</span>
<span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="st">"selection_files"</span>)

<span class="co"># Write out Raven example selection tables as physical files</span>
out &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="cf">function</span>(x) 
  <span class="kw"><a href="https://rdrr.io/r/base/writeLines.html">writeLines</a></span>(selection_files[[x]], <span class="dt">con =</span> <span class="kw"><a href="https://rdrr.io/r/base/names.html">names</a></span>(selection_files)[x]))

<span class="co"># Write example sound files out as physical .wav files</span>
<span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="dt">list =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Phae.long1"</span>, <span class="st">"Phae.long2"</span>))

<span class="kw">writeWave</span>(Phae.long1, <span class="st">"Phae.long1.wav"</span>)
<span class="kw">writeWave</span>(Phae.long2, <span class="st">"Phae.long2.wav"</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Import selections</span>
sels &lt;-<span class="st"> </span><span class="kw">imp_raven</span>(<span class="dt">all.data =</span> <span class="ot">FALSE</span>, <span class="dt">freq.cols =</span> <span class="ot">FALSE</span>, <span class="dt">warbler.format =</span> <span class="ot">TRUE</span>)
<span class="kw"><a href="https://rdrr.io/r/utils/str.html">str</a></span>(sels)

<span class="co"># Write out the imported selections as a .csv for later use</span>
<span class="kw"><a href="https://rdrr.io/r/utils/write.table.html">write.csv</a></span>(sels, <span class="st">"Raven_sels.csv"</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div id="make-your-data-frame-into-an-object-of-class-selection-table" class="section level3">
<h3 class="hasAnchor">
<a href="#make-your-data-frame-into-an-object-of-class-selection-table" class="anchor"></a>Make your data frame into an object of class <code>selection table</code>
</h3>
<p>Downstream <code>warbleR</code> functions require selection tables in order to run correctly. Use the function <code>selection_table</code> to convert your data frame into an object of class <code>selection_table</code>. In future versions of <code>warbleR</code>, all functions will require selection table objects of class <code>selection_table</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sels &lt;-<span class="st"> </span><span class="kw"><a href="../reference/selection_table.html">selection_table</a></span>(<span class="dt">X =</span> sels)
<span class="kw"><a href="https://rdrr.io/r/utils/str.html">str</a></span>(sels)
<span class="kw"><a href="https://rdrr.io/r/base/class.html">class</a></span>(sels)</code></pre></div>
</div>
</div>
<div id="obtain-metadata-and-recordings-from-xeno-canto" class="section level2">
<h2 class="hasAnchor">
<a href="#obtain-metadata-and-recordings-from-xeno-canto" class="anchor"></a><strong>Obtain metadata and recordings from <a href="http://www.xeno-canto.org/">xeno-canto</a></strong>
</h2>
<p>The open-access <a href="http://www.xeno-canto.org/">xeno-canto</a> database is an excellent source of sound files across avian species. You can query this database by a species or genus of interest. The function <code>querxc</code> has two types of output:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Metadata of recordings:</strong> geographic coordinates, recording quality, recordist, type of signal, etc.</p></li>
<li><p><strong>Sound files:</strong> Sound files in <em>mp3</em> format are returned if the argument <code>download</code> is set to <code>TRUE</code>.</p></li>
</ol>
<p>We recommend downloading metadata first from <em>xeno-canto</em>, as this data can be filtered in R to more efficiently download recordings (e.g. only those relevant to your question).</p>
<p>Here, we will query the <em>xeno-canto</em> database to download more <em>Phaethornis longirostris</em> sound files for our question of how male songs vary at a microgeographic scale.</p>
<p> </p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Query xeno-canto for all Phaethornis recordings (e.g., by genus)</span>
Phae &lt;-<span class="st"> </span><span class="kw"><a href="../reference/querxc.html">querxc</a></span>(<span class="dt">qword =</span> <span class="st">"Phaethornis"</span>, <span class="dt">download =</span> <span class="ot">FALSE</span>) 

<span class="co"># Check out the structure of resulting the data frame</span>
<span class="kw"><a href="https://rdrr.io/r/utils/str.html">str</a></span>(Phae)</code></pre></div>
<pre><code>'data.frame':   899 obs. of  36 variables:
 $ Recording_ID     : int  406968 403856 403854 387711 275252 261696 261695 261694 261693 261692 ...
 $ Genus            : chr  "Phaethornis" "Phaethornis" "Phaethornis" "Phaethornis" ...
 $ Specific_epithet : chr  "yaruqui" "yaruqui" "yaruqui" "yaruqui" ...
 $ Subspecies       : chr  "" "" "" "" ...
 $ English_name     : chr  "White-whiskered Hermit" "White-whiskered Hermit" "White-whiskered Hermit" "White-whiskered Hermit" ...
 $ Recordist        : chr  "Myornis" "Myornis" "Myornis" "Jerome Fischer" ...
 $ Country          : chr  "Colombia" "Colombia" "Colombia" "Ecuador" ...
 $ Locality         : chr  "La Chocoana, Guachalito, Nuquí, Chocó" "La Chocoana, Guachalito, Nuquí, Chocó" "La Chocoana, Guachalito, Nuquí, Chocó" "Amagusa Reserve Pichincha" ...
 $ Latitude         : num  5.627 5.627 5.627 0.161 0.75 ...
 $ Longitude        : num  -77.4 -77.4 -77.4 -78.9 -78.9 ...
 $ Vocalization_type: chr  "flight call" "flight call" "flight call" "song" ...
 $ Audio_file       : chr  "//www.xeno-canto.org/406968/download" "//www.xeno-canto.org/403856/download" "//www.xeno-canto.org/403854/download" "//www.xeno-canto.org/387711/download" ...
 $ License          : chr  "//creativecommons.org/licenses/by-nc-sa/4.0/" "//creativecommons.org/licenses/by-nc-sa/4.0/" "//creativecommons.org/licenses/by-nc-sa/4.0/" "//creativecommons.org/licenses/by-nc-sa/4.0/" ...
 $ Url              : chr  "//www.xeno-canto.org/406968" "//www.xeno-canto.org/403856" "//www.xeno-canto.org/403854" "//www.xeno-canto.org/387711" ...
 $ Quality          : chr  "A" "A" "A" "A" ...
 $ Time             : chr  "?" "?" "?" "09:00" ...
 $ Date             : chr  "2018-08-00" "2017-08-00" "2017-08-00" "2017-09-24" ...
 $ Altitude         : chr  "30" "10" "10" "1300" ...
 $ Spectrogram_small: chr  "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC406968-small.png" "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC403856-small.png" "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC403854-small.png" "//www.xeno-canto.org/sounds/uploaded/JPBSNBUUEF/ffts/XC387711-small.png" ...
 $ Spectrogram_med  : chr  "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC406968-med.png" "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC403856-med.png" "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC403854-med.png" "//www.xeno-canto.org/sounds/uploaded/JPBSNBUUEF/ffts/XC387711-med.png" ...
 $ Spectrogram_large: chr  "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC406968-large.png" "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC403856-large.png" "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC403854-large.png" "//www.xeno-canto.org/sounds/uploaded/JPBSNBUUEF/ffts/XC387711-large.png" ...
 $ Spectrogram_full : chr  "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC406968-full.png" "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC403856-full.png" "//www.xeno-canto.org/sounds/uploaded/OXSIOLJJUP/ffts/XC403854-full.png" "//www.xeno-canto.org/sounds/uploaded/JPBSNBUUEF/ffts/XC387711-full.png" ...
 $ Length           : chr  "0:02" "0:04" "0:01" "0:50" ...
 $ Uploaded         : chr  "2018-03-23" "2018-02-28" "2018-02-28" "2017-09-27" ...
 $ Other_species    : chr  "" "Coereba flaveola" "" "" ...
 $ Remarks          : chr  "In forest." "Forest border." "Forest border." "" ...
 $ Bird_seen        : chr  "yes" "yes" "yes" "yes" ...
 $ Playback_used    : chr  "no" "no" "no" "no" ...
 $ Other_species1   : chr  NA NA NA NA ...
 $ Other_species2   : chr  NA NA NA NA ...
 $ Other_species3   : chr  NA NA NA NA ...
 $ Other_species4   : chr  NA NA NA NA ...
 $ Other_species5   : chr  NA NA NA NA ...
 $ Other_species6   : chr  NA NA NA NA ...
 $ Other_species7   : chr  NA NA NA NA ...
 $ Other_species8   : chr  NA NA NA NA ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Query xeno-canto for all Phaethornis longirostris recordings</span>
Phae.lon &lt;-<span class="st"> </span><span class="kw"><a href="../reference/querxc.html">querxc</a></span>(<span class="dt">qword =</span> <span class="st">"Phaethornis longirostris"</span>, <span class="dt">download =</span> <span class="ot">FALSE</span>) 

<span class="co"># Check out the structure of resulting the data frame</span>
<span class="kw"><a href="https://rdrr.io/r/utils/str.html">str</a></span>(Phae.lon)</code></pre></div>
<pre><code>'data.frame':   85 obs. of  31 variables:
 $ Recording_ID     : int  497036 495384 433645 402755 355350 282529 274377 271499 154138 154129 ...
 $ Genus            : chr  "Phaethornis" "Phaethornis" "Phaethornis" "Phaethornis" ...
 $ Specific_epithet : chr  "longirostris" "longirostris" "longirostris" "longirostris" ...
 $ Subspecies       : chr  "" "cephalus" "" "" ...
 $ English_name     : chr  "Long-billed Hermit" "Long-billed Hermit" "Long-billed Hermit" "Long-billed Hermit" ...
 $ Recordist        : chr  "Jerome Fischer" "Guy Kirwan" "Oscar Campbell" "Marilyn Castillo" ...
 $ Country          : chr  "Panama" "Panama" "Panama" "Mexico" ...
 $ Locality         : chr  "Achiote Road, Colón Province" "Panama Rainforest Discovery Centre" "Panama Rainforest Discovery Centre" "Boca de Chajul, Marqués de Comillas, Chiapas" ...
 $ Latitude         : num  9.2 9.13 9.13 16.13 8.94 ...
 $ Longitude        : num  -80 -79.7 -79.7 -90.9 -78.5 ...
 $ Vocalization_type: chr  "song" "call" "song" "alarm call" ...
 $ Audio_file       : chr  "//www.xeno-canto.org/497036/download" "//www.xeno-canto.org/495384/download" "//www.xeno-canto.org/433645/download" "//www.xeno-canto.org/402755/download" ...
 $ License          : chr  "//creativecommons.org/licenses/by-nc-sa/4.0/" "//creativecommons.org/licenses/by-nc-sa/4.0/" "//creativecommons.org/licenses/by-nc-sa/4.0/" "//creativecommons.org/licenses/by-nc-nd/4.0/" ...
 $ Url              : chr  "//www.xeno-canto.org/497036" "//www.xeno-canto.org/495384" "//www.xeno-canto.org/433645" "//www.xeno-canto.org/402755" ...
 $ Quality          : chr  "no score" "A" "A" "A" ...
 $ Time             : chr  "09:30" "09:00" "08:30" "07:30" ...
 $ Date             : chr  "2019-02-10" "2019-07-04" "2018-07-10" "2016-01-18" ...
 $ Altitude         : chr  "30" "70" "70" "180" ...
 $ Spectrogram_small: chr  "//www.xeno-canto.org/sounds/uploaded/JPBSNBUUEF/ffts/XC497036-small.png" "//www.xeno-canto.org/sounds/uploaded/BZVYBRUAAE/ffts/XC495384-small.png" "//www.xeno-canto.org/sounds/uploaded/RFRTVEHIZX/ffts/XC433645-small.png" "//www.xeno-canto.org/sounds/uploaded/CHRIDPJVMH/ffts/XC402755-small.png" ...
 $ Spectrogram_med  : chr  "//www.xeno-canto.org/sounds/uploaded/JPBSNBUUEF/ffts/XC497036-med.png" "//www.xeno-canto.org/sounds/uploaded/BZVYBRUAAE/ffts/XC495384-med.png" "//www.xeno-canto.org/sounds/uploaded/RFRTVEHIZX/ffts/XC433645-med.png" "//www.xeno-canto.org/sounds/uploaded/CHRIDPJVMH/ffts/XC402755-med.png" ...
 $ Spectrogram_large: chr  "//www.xeno-canto.org/sounds/uploaded/JPBSNBUUEF/ffts/XC497036-large.png" "//www.xeno-canto.org/sounds/uploaded/BZVYBRUAAE/ffts/XC495384-large.png" "//www.xeno-canto.org/sounds/uploaded/RFRTVEHIZX/ffts/XC433645-large.png" "//www.xeno-canto.org/sounds/uploaded/CHRIDPJVMH/ffts/XC402755-large.png" ...
 $ Spectrogram_full : chr  "//www.xeno-canto.org/sounds/uploaded/JPBSNBUUEF/ffts/XC497036-full.png" "//www.xeno-canto.org/sounds/uploaded/BZVYBRUAAE/ffts/XC495384-full.png" "//www.xeno-canto.org/sounds/uploaded/RFRTVEHIZX/ffts/XC433645-full.png" "//www.xeno-canto.org/sounds/uploaded/CHRIDPJVMH/ffts/XC402755-full.png" ...
 $ Length           : chr  "0:27" "0:49" "0:58" "0:03" ...
 $ Uploaded         : chr  "2019-09-13" "2019-09-01" "2018-09-09" "2018-02-14" ...
 $ Other_species    : chr  "" "" "" "" ...
 $ Remarks          : chr  "" "Lek with up to three different individuals. Focal bird was perched 1.5 m above ground on a 45-degree angle twig." "Male seen on lek; 3 feet above ground in gap in undergrowth. Calling incessantly and quivering tail as doing so"| __truncated__ "" ...
 $ Bird_seen        : chr  "yes" "yes" "yes" "yes" ...
 $ Playback_used    : chr  "no" "no" "no" "no" ...
 $ Other_species1   : chr  NA NA NA NA ...
 $ Other_species2   : chr  NA NA NA NA ...
 $ Other_species3   : chr  NA NA NA NA ...</code></pre>
<p> </p>
<p>You can then use the function <code>xcmaps</code> to visualize the geographic spread of the queried recordings. <code>xcmaps</code> will create an image file of a map per species in your current directory if <code>img = TRUE</code>. If <code>img = FALSE</code>, maps will be displayed in the graphics device.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Image type default is jpeg, but tiff files have better resolution</span>

<span class="co"># When the data frame contains multiple species, this will yield one map per species</span>
<span class="kw"><a href="../reference/xcmaps.html">xcmaps</a></span>(<span class="dt">X =</span> Phae, <span class="dt">img =</span> <span class="ot">TRUE</span>, <span class="dt">it =</span> <span class="st">"tiff"</span>) <span class="co"># all species in the genus</span>
<span class="kw"><a href="../reference/xcmaps.html">xcmaps</a></span>(<span class="dt">X =</span> Phae.lon, <span class="dt">img =</span> <span class="ot">FALSE</span>) <span class="co"># a single species</span></code></pre></div>
<div id="filter-xeno-canto-recordings-by-quality-signal-type-and-locality" class="section level3">
<h3 class="hasAnchor">
<a href="#filter-xeno-canto-recordings-by-quality-signal-type-and-locality" class="anchor"></a>Filter <a href="http://www.xeno-canto.org/">xeno-canto</a> recordings by quality, signal type and locality</h3>
<p>In most cases, you will need to filter the <em>xeno-canto</em> metadata by type of signal you want to analyze. When you subset the metadata, you can input the filtered metadata back into <code>querxc</code> to download only the selected recordings. There are many ways to filter data in R, and the example below can be modified to fit your own data.</p>
<p>Here, before downloading the sound files themselves from <em>xeno-canto</em>, we want to ensure that we select high quality sound files that contain songs (rather than other acoustic signal types) and were also recorded at La Selva Biological Station in Costa Rica.</p>
<p> </p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># How many recordings are available for Phaethornis longirostris?</span>
<span class="kw"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(Phae.lon) </code></pre></div>
<pre><code>[1] 85</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># How many signal types exist in the xeno-canto metadata?</span>
<span class="kw"><a href="https://rdrr.io/r/base/levels.html">levels</a></span>(Phae.lon<span class="op">$</span>Vocalization_type)</code></pre></div>
<pre><code>NULL</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># How many recordings per signal type?</span>
<span class="kw"><a href="https://rdrr.io/r/base/table.html">table</a></span>(Phae.lon<span class="op">$</span>Vocalization_type)</code></pre></div>
<pre><code>
              300        alarm call              call             calls       flight call         lek, song           lekking              song 
                1                 1                 6                 1                 2                 2                 1                68 
      song at lek song, wing whirrs 
                2                 1 </code></pre>
<p> </p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Filter the metadata to select the signals we want to retain</span>

<span class="co"># First by quality</span>
Phae.lon &lt;-<span class="st"> </span>Phae.lon[Phae.lon<span class="op">$</span>Quality <span class="op">==</span><span class="st"> "A"</span>, ]
<span class="kw"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(Phae.lon)</code></pre></div>
<pre><code>[1] 12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Then by signal type</span>
Phae.lon.song &lt;-<span class="st"> </span>Phae.lon[<span class="kw"><a href="https://rdrr.io/r/base/grep.html">grep</a></span>(<span class="st">"song"</span>, Phae.lon<span class="op">$</span>Vocalization_type, <span class="dt">ignore.case =</span> <span class="ot">TRUE</span>), ]
<span class="kw"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(Phae.lon.song)</code></pre></div>
<pre><code>[1] 9</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Finally by locality</span>
Phae.lon.LS &lt;-<span class="st"> </span>Phae.lon.song[<span class="kw"><a href="https://rdrr.io/r/base/grep.html">grep</a></span>(<span class="st">"La Selva Biological Station, Sarapiqui, Heredia"</span>, Phae.lon.song<span class="op">$</span>Locality, <span class="dt">ignore.case =</span> <span class="ot">FALSE</span>), ]

<span class="co"># Check resulting data frame, 6 recordings remain</span>
<span class="kw"><a href="https://rdrr.io/r/utils/str.html">str</a></span>(Phae.lon.LS)</code></pre></div>
<pre><code>'data.frame':   3 obs. of  31 variables:
 $ Recording_ID     : int  154138 154129 154072
 $ Genus            : chr  "Phaethornis" "Phaethornis" "Phaethornis"
 $ Specific_epithet : chr  "longirostris" "longirostris" "longirostris"
 $ Subspecies       : chr  "" "" ""
 $ English_name     : chr  "Long-billed Hermit" "Long-billed Hermit" "Long-billed Hermit"
 $ Recordist        : chr  "Marcelo Araya-Salas" "Marcelo Araya-Salas" "Marcelo Araya-Salas"
 $ Country          : chr  "Costa Rica" "Costa Rica" "Costa Rica"
 $ Locality         : chr  "La Selva Biological Station, Sarapiqui, Heredia" "La Selva Biological Station, Sarapiqui, Heredia" "La Selva Biological Station, Sarapiqui, Heredia"
 $ Latitude         : num  10.4 10.4 10.4
 $ Longitude        : num  -84 -84 -84
 $ Vocalization_type: chr  "song" "song" "song"
 $ Audio_file       : chr  "//www.xeno-canto.org/154138/download" "//www.xeno-canto.org/154129/download" "//www.xeno-canto.org/154072/download"
 $ License          : chr  "//creativecommons.org/licenses/by-nc-sa/3.0/" "//creativecommons.org/licenses/by-nc-sa/3.0/" "//creativecommons.org/licenses/by-nc-sa/3.0/"
 $ Url              : chr  "//www.xeno-canto.org/154138" "//www.xeno-canto.org/154129" "//www.xeno-canto.org/154072"
 $ Quality          : chr  "A" "A" "A"
 $ Time             : chr  "14:18" "10:09" "7:05"
 $ Date             : chr  "2010-05-21" "2010-05-21" "2010-05-28"
 $ Altitude         : chr  "" "" ""
 $ Spectrogram_small: chr  "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154138-small.png" "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154129-small.png" "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154072-small.png"
 $ Spectrogram_med  : chr  "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154138-med.png" "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154129-med.png" "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154072-med.png"
 $ Spectrogram_large: chr  "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154138-large.png" "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154129-large.png" "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154072-large.png"
 $ Spectrogram_full : chr  "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154138-full.png" "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154129-full.png" "//www.xeno-canto.org/sounds/uploaded/EMCWQLLKEW/ffts/XC154072-full.png"
 $ Length           : chr  "2:58" "2:25" "3:09"
 $ Uploaded         : chr  "2013-11-11" "2013-11-11" "2013-11-11"
 $ Other_species    : chr  "" "" ""
 $ Remarks          : chr  "Recording equipment: Marantz Pmd 660+sennheiser ME67. Comments: individuo-AK; lek-Sura. Primera parte de grabac"| __truncated__ "Recording equipment: Marantz Pmd 660+sennheiser ME67. Comments: individuo-AK; lek-Sura. video 511, revisar. 9 m"| __truncated__ "Recording equipment: Marantz Pmd 660+sennheiser ME67. Comments: individuo-VA; lek-CCL. en percha ded VA, probab"| __truncated__
 $ Bird_seen        : chr  "yes" "yes" "yes"
 $ Playback_used    : chr  "no" "no" "no"
 $ Other_species1   : chr  NA NA NA
 $ Other_species2   : chr  NA NA NA
 $ Other_species3   : chr  NA NA NA</code></pre>
<p> </p>
<p>We can check if the location coordinates make sense (all recordings should be from a single place in Costa Rica) by making a map of these recordings using <code>xcmaps</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># map in the RStudio graphics device (img = FALSE)</span>
<span class="kw"><a href="../reference/xcmaps.html">xcmaps</a></span>(Phae.lon.LS, <span class="dt">img =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p> </p>
<p>Once you’re sure you want the recordings, use <code>querxc</code> to download the files. Also, save the metadata as a <em>.csv</em> file.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Download sound files</span>
<span class="kw"><a href="../reference/querxc.html">querxc</a></span>(<span class="dt">X =</span> Phae.lon.LS) 

<span class="co"># Save the metadata object as a .csv file </span>
<span class="kw"><a href="https://rdrr.io/r/utils/write.table.html">write.csv</a></span>(Phae.lon.LS, <span class="st">"Phae_lon.LS.csv"</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p> </p>
</div>
<div id="convert-xeno-canto-mp3-recordings-to-wav-format" class="section level3">
<h3 class="hasAnchor">
<a href="#convert-xeno-canto-mp3-recordings-to-wav-format" class="anchor"></a>Convert <a href="http://www.xeno-canto.org/">xeno-canto</a> <em>mp3</em> recordings to <em>wav</em> format</h3>
<p><a href="http://www.xeno-canto.org/">xeno-canto</a> maintains recordings in <em>mp3</em> format due to file size restrictions. However, we require <em>wav</em> format for all downstream analyses. Compression from <em>wav</em> to <em>mp3</em> and back involves information losses, but recordings that have undergone this transformation have been successfully used in research <a href="#References"> <sup>[3]</sup></a>.</p>
<p>To convert <em>mp3</em> to <em>wav</em>, we can use the warbleR function <code>mp32wav</code>, which relies on a underlying function from the <a href="https://cran.r-project.org/package=tuneR"><code>tuneR</code></a> package. This function does not always work (and it remains unclear as to why!). This bug should be fixed in future versions of <code>tuneR</code>. If RStudio aborts when running <code>mp32wav</code>, use an <em>mp3</em> to <em>wav</em> converter online, or download the open source software <code>Audacity</code> (available for Mac, Linux and Windows users).</p>
<p>After <em>mp3</em> files have been converted, we need to check that the <em>wav</em> files are not corrupted and can be read into RStudio (some <em>wav</em> files can’t be read due to format or permission issues).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Always check you're in the right directory beforehand</span>
<span class="co"># getwd()</span>

<span class="co"># here we are downsampling the original sampling rate of 44.1 kHz to speed up downstream analyses in the vignette series</span>
<span class="kw"><a href="../reference/mp32wav.html">mp32wav</a></span>(<span class="dt">samp.rate =</span> <span class="fl">22.05</span>) 

<span class="co"># Use checkwavs to see if wav files can be read</span>
<span class="kw"><a href="../reference/checkwavs.html">checkwavs</a></span>() </code></pre></div>
<p> </p>
</div>
</div>
<div id="a-note-on-combining-data-from-different-sources" class="section level2">
<h2 class="hasAnchor">
<a href="#a-note-on-combining-data-from-different-sources" class="anchor"></a><strong>A note on combining data from different sources</strong>
</h2>
<p>We now have <em>.wav</em> files for existing recordings ( <em>Phae.long1.wav</em> through <em>Phae.long4.wav</em>, representing recordings made in the field) as well as 6 recordings downloaded from <em>xeno-canto</em>. The existing Phae.long*.wav recordings have associated selection tables that were made in <em>Raven</em>, but the <em>xeno-canto</em> have no selection tables, as we have not parsed these sound files to select signals within them.</p>
<p>Depending on your question(s), you can combine your own sound files and those from <code>xeno-canto</code> into a single data set (after ground-truthing). This is made possible by the fact that <code>warbleR</code> functions will read in all sound files present in your working directory.</p>
<p>For the main case study in this vignette, we will move forwards with only the <code>xeno-canto</code> sound files. We will use the example sound files when demonstrating <code>warbleR</code> functions that are not mandatory for the case study but may be useful for your own workflow (e.g. <code>consolidate</code> below).</p>
<p>To continue the workflow, remove all example <em>wav</em> files from your working directory</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make sure you are in the right working directory</span>
<span class="co"># Note that all the example sound files begin with the pattern "Phae.long"</span>
wavs &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/list.files.html">list.files</a></span>(<span class="dt">pattern =</span> <span class="st">"wav$"</span>)
wavs

rm &lt;-<span class="st"> </span>wavs[<span class="kw"><a href="https://rdrr.io/r/base/grep.html">grep</a></span>(<span class="st">"Phae.long"</span>, wavs)]

<span class="kw"><a href="https://rdrr.io/r/base/files.html">file.remove</a></span>(rm)

<span class="co"># Check that the right wav files were removed</span>
<span class="co"># Only xeno-cant wav files should remain</span>
<span class="kw"><a href="https://rdrr.io/r/base/list.files.html">list.files</a></span>(<span class="dt">pattern =</span> <span class="st">"wav$"</span>)</code></pre></div>
<div id="consolidate-sound-files-across-various-directories" class="section level3">
<h3 class="hasAnchor">
<a href="#consolidate-sound-files-across-various-directories" class="anchor"></a>Consolidate sound files across various directories</h3>
<p>Since <code>warbleR</code> handles sound files in working directories, it’s good practice to keep sound files associated with the same project in a single directory. If you’re someone who likes to make a new directory for every batch of recordings or new analysis associated with the same project, you may find the <code>consolidate</code> function useful.</p>
<p>In case you have your own recordings in <em>wav</em> format and have skipped previous sections, you must specify the location of the sound files you will use prior to running downstream functions by setting your working directory again.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># For this example, set your working directory to an empty temporary directory</span>
<span class="kw"><a href="https://rdrr.io/r/base/getwd.html">setwd</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/tempfile.html">tempdir</a></span>())

<span class="co"># Here we will simulate the problem of having files scattered in multiple directories</span>

<span class="co"># Load .wav file examples from the NatureSounds package</span>
<span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="dt">list =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Phae.long1"</span>, <span class="st">"Phae.long2"</span>, <span class="st">"Phae.long3"</span>))

<span class="co"># Create first folder inside the temporary directory and write new .wav files inside this new folder</span>
<span class="kw"><a href="https://rdrr.io/r/base/files2.html">dir.create</a></span>(<span class="st">"folder1"</span>)
<span class="kw">writeWave</span>(Phae.long1, <span class="kw"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span>(<span class="st">"folder1"</span>,<span class="st">"Phae_long1.wav"</span>))
<span class="kw">writeWave</span>(Phae.long2, <span class="kw"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span>(<span class="st">"folder1"</span>,<span class="st">"Phae_long2.wav"</span>))

<span class="co"># Create second folder inside the temporary directory and write new .wav files inside this second new folder</span>
<span class="kw"><a href="https://rdrr.io/r/base/files2.html">dir.create</a></span>(<span class="st">"folder2"</span>)
<span class="kw">writeWave</span>(Phae.long3, <span class="kw"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span>(<span class="st">"folder2"</span>,<span class="st">"Phae_long3.wav"</span>))

<span class="co"># Consolidate the scattered files into a single folder, and make a .csv file that contains metadata (location, old and new names in the case that files were renamed)</span>
<span class="kw"><a href="https://rdrr.io/r/base/invisible.html">invisible</a></span>(<span class="kw"><a href="../reference/consolidate.html">consolidate</a></span>(<span class="dt">path =</span> <span class="kw"><a href="https://rdrr.io/r/base/tempfile.html">tempdir</a></span>(), <span class="dt">save.csv =</span> <span class="ot">TRUE</span>))

<span class="kw"><a href="https://rdrr.io/r/base/list.files.html">list.files</a></span>(<span class="dt">path =</span> <span class="st">"./consolidated_folder"</span>)

<span class="co"># set your working directory back to "/home/user/warbleR_example" for the rest of the vignette, or to whatever working directory you were using originally</span></code></pre></div>
</div>
</div>
<div id="make-long-spectrograms-of-whole-recordings" class="section level2">
<h2 class="hasAnchor">
<a href="#make-long-spectrograms-of-whole-recordings" class="anchor"></a><strong>Make long spectrograms of whole recordings</strong>
</h2>
<p><code>lspec</code> produces image files with spectrograms of whole sound files split into multiple rows. It is a useful tool for filtering by visual inspection.</p>
<p><code>lspec</code> allows you to visually inspect the quality of the recording (e.g. amount of background noise) or the type, number, and completeness of the vocalizations of interest. You can discard the image files and recordings that you no longer want to analyze.</p>
<p>First, adjust the function arguments as needed. We can work on a subset of the recordings by specifying their names with the <code>flist</code> argument.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create a vector of all the recordings in the directory</span>
wavs &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/list.files.html">list.files</a></span>(<span class="dt">pattern =</span> <span class="st">"wav$"</span>)

<span class="co"># Print this object to see all sound files</span>
<span class="co"># 6 sound files from xeno-canto</span>
wavs 

<span class="co"># Select a subset of recordings to explore lspec() arguments </span>
<span class="co"># Based on the list of wav files we created above</span>
sub &lt;-<span class="st"> </span>wavs[<span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1</span>, <span class="dv">5</span>)]

<span class="co"># How long are these files? this will determine number of pages returned by lspec</span>
<span class="kw"><a href="../reference/wavdur.html">wavdur</a></span>(sub)

<span class="co"># ovlp = 10 to speed up function</span>
<span class="co"># tiff image files are better quality and are faster to produce</span>
<span class="kw"><a href="../reference/lspec.html">lspec</a></span>(<span class="dt">flist =</span> sub, <span class="dt">ovlp =</span> <span class="dv">10</span>, <span class="dt">it =</span> <span class="st">"tiff"</span>)

<span class="co"># We can zoom in on the frequency axis by changing flim, </span>
<span class="co"># the number of seconds per row, and number of rows</span>
<span class="kw"><a href="../reference/lspec.html">lspec</a></span>(<span class="dt">flist =</span> sub, <span class="dt">flim =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">2</span>, <span class="dv">10</span>), <span class="dt">sxrow =</span> <span class="dv">6</span>, <span class="dt">rows =</span> <span class="dv">15</span>, <span class="dt">ovlp =</span> <span class="dv">10</span>, <span class="dt">it =</span> <span class="st">"tiff"</span>)</code></pre></div>
<p>Once satisfied with the argument settings we can make long spectrograms for all the sound files.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Make long spectrograms for the xeno-canto sound files</span>
<span class="kw"><a href="../reference/lspec.html">lspec</a></span>(<span class="dt">flim =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">2</span>, <span class="dv">10</span>), <span class="dt">ovlp =</span> <span class="dv">10</span>, <span class="dt">sxrow =</span> <span class="dv">6</span>, <span class="dt">rows =</span> <span class="dv">15</span>, <span class="dt">it =</span> <span class="st">"jpeg"</span>, <span class="dt">flist =</span> fl)

<span class="co"># Concatenate lspec image files into a single PDF per recording</span>
<span class="co"># lspec images must be jpegs to do this</span>
<span class="kw"><a href="../reference/lspec2pdf.html">lspec2pdf</a></span>(<span class="dt">keep.img =</span> <span class="ot">FALSE</span>, <span class="dt">overwrite =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>The pdf image files (in the working directory) for the <em>xeno-canto</em> recordings should look like this:</p>
<!-- <center> ![lspec image example](Phaethornis-longirostris-154072-p1.jpg)</center>  -->
<p> </p>
<p>The sound file name and page number are placed in the top right corner. The dimensions of the image are made to letter paper size for printing and subsequent visual inspection.</p>
<p>Recording <em>154123</em> has a lot of background noise. Delete the <em>wav</em> file for this recording to remove it from subsequent analyses.</p>
</div>
<div id="select-signals-in-warbler" class="section level2">
<h2 class="hasAnchor">
<a href="#select-signals-in-warbler" class="anchor"></a><strong>Select signals in <em>warbleR</em></strong>
</h2>
<p><em>warbleR</em> has two main functions for selecting acoustic signals within recordings. <code>autodetec</code> automatically detects the start and end of signals in sound files based on amplitude, duration, and frequency range attributes. <code>manualoc</code> provides an interactive interface in the graphics device to manually select signals</p>
<p>Both functions are fastest with shorter recordings, but there are ways to deal with larger recordings (an hour long or more). In this section we have expanded on some important function arguments, but check out the function documentation for more information.</p>
<div id="automatically-detect-signals-with-autodetec" class="section level3">
<h3 class="hasAnchor">
<a href="#automatically-detect-signals-with-autodetec" class="anchor"></a>Automatically detect signals with <code>autodetec</code>
</h3>
<p><code>autodetec</code> has 2 types of output:** + data frame with recording name, selection, start and end times. The last two are temporal coordinates that will be passed on to downstream functions to measure acoustic parameters + a spectrogram per recording, with red dotted lines marking the start and end of each detected signal, saved in your working directory</p>
<p>Check out the <code>autodetec</code> documentation for more information. The argument <code>threshold</code> is one of the most important detection parameters, as well as information about signal frequency range and duration. <em>Phaethornis longirostris</em> songs have frequencies between 2 and 10 kHz and durations between 0.05 and 0.5 s.</p>
<p>If you need to detect all or most of the signals within the recording, play around with different arguments to increase detection accuracy. Since you may need to do several rounds of optimization, we recommend using subsets of your recordings to speed up the process. If the species you study produces stereotyped signals, like <em>Phaethornis longirostris</em>, just a few signals are needed per recording, and a low-accuracy detection could yield enough selections.</p>
<p><code>autodetec</code> does not replace visual inspection of selected signals. Ensure that you set aside the time to inspect all selected signals for accuracy. You will often need to run detection functions several times, and in the process you will get to know your signals better (if you don’t already).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Select a subset of sound files</span>
<span class="co"># Reinitialize the wav object</span>
wavs &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/list.files.html">list.files</a></span>(<span class="dt">pattern =</span> <span class="st">".wav$"</span>, <span class="dt">ignore.case =</span> <span class="ot">TRUE</span>)

<span class="co"># Set a seed so we all have the same results</span>
<span class="kw"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="dv">1</span>)
sub &lt;-<span class="st"> </span>wavs[<span class="kw"><a href="https://rdrr.io/r/base/sample.html">sample</a></span>(<span class="dv">1</span><span class="op">:</span><span class="kw"><a href="https://rdrr.io/r/base/length.html">length</a></span>(wavs), <span class="dv">3</span>)]

<span class="co"># Run autodetec() on subset of recordings</span>
<span class="co"># The data frame object output is printed to the console, we are not saving this in an object yet, since we are just playing around with argument settings</span>
<span class="co"># you can run this in parallel to speed up computation time</span>
<span class="kw"><a href="../reference/autodetec.html">autodetec</a></span>(<span class="dt">flist =</span> sub, <span class="dt">bp =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1</span>, <span class="dv">10</span>), <span class="dt">threshold =</span> <span class="dv">10</span>, <span class="dt">mindur =</span> <span class="fl">0.05</span>, <span class="dt">maxdur =</span> <span class="fl">0.5</span>, <span class="dt">envt=</span><span class="st">"abs"</span>, <span class="dt">ssmooth =</span> <span class="dv">300</span>, <span class="dt">ls =</span> <span class="ot">TRUE</span>, <span class="dt">res =</span> <span class="dv">100</span>, <span class="dt">flim =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1</span>, <span class="dv">12</span>), <span class="dt">wl =</span> <span class="dv">300</span>, <span class="dt">set =</span> <span class="ot">TRUE</span>, <span class="dt">sxrow =</span> <span class="dv">6</span>, <span class="dt">rows =</span> <span class="dv">15</span>, <span class="dt">redo =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>Check out the image files in your working directory. Note that some songs were correctly detected but other undesired sounds were also detected. In most cases, the undesired selections have a shorter duration than our target signals.</p>
<p>We won’t save the <code>autodetec</code> ouput in an object until we’re satisfied with the detection. To improve our detection we should play around with argument values. Also note that the image files produced by <code>autodetec</code> contain the values used for the different arguments, which can help you better compare between runs. Below are some detection parameters that work well for these <em>Phaethornis longirostris </em> recordings:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/autodetec.html">autodetec</a></span>(<span class="dt">flist =</span> sub, <span class="dt">bp =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">2</span>, <span class="dv">10</span>), <span class="dt">threshold =</span> <span class="dv">20</span>, <span class="dt">mindur =</span> <span class="fl">0.09</span>, <span class="dt">maxdur =</span> <span class="fl">0.22</span>, <span class="dt">envt =</span> <span class="st">"abs"</span>, <span class="dt">ssmooth =</span> <span class="dv">900</span>, <span class="dt">ls =</span> <span class="ot">TRUE</span>, <span class="dt">res =</span> <span class="dv">100</span>, <span class="dt">flim=</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1</span>, <span class="dv">12</span>), <span class="dt">wl =</span> <span class="dv">300</span>, <span class="dt">set =</span><span class="ot">TRUE</span>, <span class="dt">sxrow =</span> <span class="dv">6</span>, <span class="dt">rows =</span> <span class="dv">15</span>, <span class="dt">redo =</span> <span class="ot">TRUE</span>, <span class="dt">it =</span> <span class="st">"tiff"</span>, <span class="dt">img =</span> <span class="ot">TRUE</span>, <span class="dt">smadj =</span> <span class="st">"end"</span>)</code></pre></div>
<p>This seems to provide a good detection for most recordings (recording ID 154161):</p>
<center>
<img src="154161-autodetec.th15.jpg" alt="autodetec image example">
</center>
<p> </p>
<p>Once we’re satisfied with the detection, we can run the <code>autodetec</code> on all the recordings, removing the argument <code>flist</code> (so <code>autodetec</code> runs over all <em>wav</em> files in the working directory). We will also save the temporal output in an object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Phae.ad &lt;-<span class="st"> </span><span class="kw"><a href="../reference/autodetec.html">autodetec</a></span>(<span class="dt">bp =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">2</span>, <span class="dv">10</span>), <span class="dt">threshold =</span> <span class="dv">20</span>, <span class="dt">mindur =</span> <span class="fl">0.09</span>, <span class="dt">maxdur =</span> <span class="fl">0.22</span>, <span class="dt">envt =</span> <span class="st">"abs"</span>, <span class="dt">ssmooth =</span> <span class="dv">900</span>, <span class="dt">ls =</span> <span class="ot">TRUE</span>, <span class="dt">res =</span> <span class="dv">100</span>, <span class="dt">flim =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">2</span>, <span class="dv">10</span>), <span class="dt">wl =</span> <span class="dv">300</span>, <span class="dt">set =</span><span class="ot">TRUE</span>, <span class="dt">sxrow =</span> <span class="dv">6</span>, <span class="dt">rows =</span> <span class="dv">15</span>, <span class="dt">redo =</span> <span class="ot">TRUE</span>, <span class="dt">it =</span> <span class="st">"tiff"</span>, <span class="dt">img =</span> <span class="ot">TRUE</span>, <span class="dt">smadj =</span> <span class="st">"end"</span>)</code></pre></div>
<p>Let’s look at the number of selections per sound file:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://rdrr.io/r/base/table.html">table</a></span>(Phae.ad<span class="op">$</span>sound.files)</code></pre></div>
</div>
<div id="use-snr-to-filter-automatically-selected-signals" class="section level3">
<h3 class="hasAnchor">
<a href="#use-snr-to-filter-automatically-selected-signals" class="anchor"></a>Use SNR to filter automatically selected signals</h3>
<p>Signal-to-noise ratio (SNR) can be a useful filter for automated signal detection. When background noise is detected as a signal it will have a low SNR, and this characteristic can be used to remove background noise from the <code>autodetec</code> selection table. SNR = 1 means the signal and background noise have the same amplitude, so signals with SNR &lt;= 1 are poor quality. SNR calculations can also be used for different purposes throughout your analysis workflow.</p>
<div id="optimize-snr-measurements" class="section level4">
<h4 class="hasAnchor">
<a href="#optimize-snr-measurements" class="anchor"></a>Optimize SNR measurements</h4>
<p><code>snrspecs</code> is a function in the family of spectrogram creators that allows you to pick a margin for measuring noise. These margins are very important for calculating SNR, especially when working with signals separated by short gaps (e.g. duets).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># A margin that's too large causes other signals to be included in the noise measurement</span>
<span class="co"># Re-initialize X as needed, for either autodetec or manualoc output</span>

<span class="co"># Try this with 10% of the selections first</span>
<span class="co"># Set a seed first, so we all have the same results</span>
<span class="kw"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="dv">5</span>)

X &lt;-<span class="st"> </span>Phae.ad[<span class="kw"><a href="https://rdrr.io/r/base/sample.html">sample</a></span>(<span class="dv">1</span><span class="op">:</span><span class="kw"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(Phae.ad),(<span class="kw"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(Phae.ad)<span class="op">*</span><span class="fl">0.05</span>)), ]
<span class="kw"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(X)

<span class="kw"><a href="../reference/snrspecs.html">snrspecs</a></span>(<span class="dt">X =</span> X, <span class="dt">flim =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">2</span>, <span class="dv">10</span>), <span class="dt">snrmar =</span> <span class="fl">0.5</span>, <span class="dt">mar =</span> <span class="fl">0.7</span>, <span class="dt">it =</span> <span class="st">"jpeg"</span>)</code></pre></div>
<p>Check out the image files in your working directory. This margin overlaps neighboring signals, so a smaller margin would be better.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># This smaller margin is better</span>
<span class="kw"><a href="../reference/snrspecs.html">snrspecs</a></span>(<span class="dt">X =</span> X, <span class="dt">flim =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">2</span>, <span class="dv">10</span>), <span class="dt">snrmar =</span> <span class="fl">0.04</span>, <span class="dt">mar =</span> <span class="fl">0.7</span>, <span class="dt">it =</span> <span class="st">"jpeg"</span>)</code></pre></div>
<!-- <center> ![snrpecs image example](Phaethornis-longirostris-154161.wav-113-snr2.jpeg) </center> -->
<p> </p>
</div>
<div id="calculate-snr-for-automatically-selected-signals" class="section level4">
<h4 class="hasAnchor">
<a href="#calculate-snr-for-automatically-selected-signals" class="anchor"></a>Calculate SNR for automatically selected signals</h4>
<p>Once we’ve picked an SNR margin we can move forward with the SNR calculation. We will measure SNR on every other selection to speed up the process.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Phae.snr &lt;-<span class="st"> </span><span class="kw"><a href="../reference/sig2noise.html">sig2noise</a></span>(<span class="dt">X =</span> Phae.ad[<span class="kw"><a href="https://rdrr.io/r/base/seq.html">seq</a></span>(<span class="dv">1</span>, <span class="kw"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(Phae.ad), <span class="dv">2</span>), ], <span class="dt">mar =</span> <span class="fl">0.04</span>)</code></pre></div>
<p>As we just need a few songs to characterize individuals (here sound files are equivalent to different individuals), we can choose selections with the highest SNR per sound file. In this example, we will choose 5 selections per recording with the highest SNRs.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Phae.hisnr &lt;-<span class="st"> </span>Phae.snr[<span class="kw"><a href="https://rdrr.io/r/stats/ave.html">ave</a></span>(<span class="op">-</span>Phae.snr<span class="op">$</span>SNR, Phae.snr<span class="op">$</span>sound.files, <span class="dt">FUN =</span> rank) <span class="op">&lt;=</span><span class="st"> </span><span class="dv">5</span>, ]

<span class="co"># save the selections as a physical file</span>
<span class="kw"><a href="https://rdrr.io/r/utils/write.table.html">write.csv</a></span>(Phae.hisnr, <span class="st">"Phae_hisnr.csv"</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)

<span class="co"># Double check the number of selection per sound files</span>
<span class="co"># Only the xeno-canto sound files will have 5 selections, the other sound files started off with less than 5 selections</span>
<span class="kw"><a href="https://rdrr.io/r/base/table.html">table</a></span>(Phae.hisnr<span class="op">$</span>sound.files)</code></pre></div>
<p> </p>
</div>
</div>
<div id="manually-select-signals-with-manualoc" class="section level3">
<h3 class="hasAnchor">
<a href="#manually-select-signals-with-manualoc" class="anchor"></a>Manually select signals with <code>manualoc</code>
</h3>
<p>Note: <code>manualoc</code> will be deprecated in future versions of <code>warbleR</code></p>
<p><code>manualoc</code> is a function that provides an interactive interface to select signals. Check out the <code>manualoc</code> documentation prior to running this example. This function makes a selection table as a <em>.csv</em> file in your working directory.</p>
<p><code>manualoc</code> now opens an external graphics device for selecting signals. You can stop the function at any point by clicking twice on the <code>stop</code> button.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Run manualoc() with frequency range set for Phaethornis longirostris</span>
<span class="co"># Recording comments are enabled to mark recording quality</span>
<span class="co"># Selection comments enabled to include visual classifications</span>
<span class="kw"><a href="../reference/manualoc.html">manualoc</a></span>(<span class="dt">flim =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">2</span>, <span class="dv">10</span>), <span class="dt">reccomm =</span> <span class="ot">TRUE</span>, <span class="dt">selcomm =</span> <span class="ot">TRUE</span>, <span class="dt">osci =</span> <span class="ot">TRUE</span>, <span class="dt">seltime =</span> <span class="dv">2</span>)

<span class="co"># Read manualoc() output back into R as an object</span>
<span class="co"># This data frame object can be used as input for later functions</span>
manualoc_out &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span>(<span class="st">"manualoc_output.csv"</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)</code></pre></div>
</div>
</div>
<div id="next-vignette-visual-inspection-and-signal-classification" class="section level2">
<h2 class="hasAnchor">
<a href="#next-vignette-visual-inspection-and-signal-classification" class="anchor"></a><strong>Next vignette: Visual inspection and signal classification</strong>
</h2>
<p>Here we have given examples of how to begin the <code>warbleR</code> workflow. Note that there are many different ways to begin the workflow, depending on your question and source of data. After running the code in this first vignette, you should now have an idea of:</p>
<ul>
<li>the type of data used in <em>warbleR</em> (sound files and selections)</li>
<li>how to import <em>Raven</em> selection tables for your own sound files</li>
<li>how to obtain open-access <em>xeno-canto</em> sound files</li>
<li>how to create long spectrograms of recordings for visual inspection</li>
<li>how to select signals within sound files in <code>warbleR</code>
<ul>
<li>automatic selection</li>
<li>filtering automatically selected signals using SNR</li>
<li>manual selection</li>
</ul>
</li>
</ul>
<p>The next vignette will cover the second phase of the <em>warbleR</em> workflow, which includes methods to visualize signals for quality control and classification.</p>
</div>
<div id="citation" class="section level2">
<h2 class="hasAnchor">
<a href="#citation" class="anchor"></a><strong>Citation</strong>
</h2>
<p>Please cite <code>warbleR</code> when you use the package:</p>
<p>Araya-Salas, M. and Smith-Vidaurre, G. (2017), warbleR: an R package to streamline analysis of animal acoustic signals. Methods Ecol Evol. 8, 184-191.</p>
</div>
<div id="reporting-bugs" class="section level2">
<h2 class="hasAnchor">
<a href="#reporting-bugs" class="anchor"></a><strong>Reporting bugs</strong>
</h2>
<p>Please report any bugs <a href="https://github.com/maRce10/warbleR/issues">here</a>.  </p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a><font size="5"><a name="References">References</a></font>
</h2>
<ol style="list-style-type: decimal">
<li><p>Araya-Salas, M. and G. Smith-Vidaurre. 2016. warbleR: an R package to streamline analysis of animal acoustic signals. <em>Methods in Ecology and Evolution</em>. doi: 10.1111/2041-210X.12624</p></li>
<li><p>Araya-Salas, M. and T. Wright. 2013. Open-ended song learning in a hummingbird. <em>Biology Letters</em>. 9 (5). doi: 10.1098/rsbl.2013.0625</p></li>
<li><p>Medina‐García, Angela, M. Araya‐Salas, and T. Wright. 2015. Does vocal learning accelerate acoustic diversification? Evolution of contact calls in Neotropical parrots. <em>Journal of Evolutionary Biology</em>. doi: 10.1111/jeb.12694</p></li>
</ol>
<p> </p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#bioacoustics-in-r-with-warbler">Bioacoustics in R with <code>warbleR</code></a></li>
      <li><a href="#vignette-introduction"><strong>Vignette introduction</strong></a></li>
      <li><a href="#prepare-for-analyses"><strong>Prepare for analyses</strong></a></li>
      <li><a href="#import-selection-tables"><strong>Import selection tables</strong></a></li>
      <li><a href="#obtain-metadata-and-recordings-from-xeno-canto"><strong>Obtain metadata and recordings from <a href="http://www-xeno-canto-org/">xeno-canto</a></strong></a></li>
      <li><a href="#a-note-on-combining-data-from-different-sources"><strong>A note on combining data from different sources</strong></a></li>
      <li><a href="#make-long-spectrograms-of-whole-recordings"><strong>Make long spectrograms of whole recordings</strong></a></li>
      <li><a href="#select-signals-in-warbler"><strong>Select signals in <em>warbleR</em></strong></a></li>
      <li><a href="#next-vignette-visual-inspection-and-signal-classification"><strong>Next vignette: Visual inspection and signal classification</strong></a></li>
      <li><a href="#citation"><strong>Citation</strong></a></li>
      <li><a href="#reporting-bugs"><strong>Reporting bugs</strong></a></li>
      <li><a href="#references"><font size="5"><a name="References" href="NA">References</a></font></a></li>
      </ul>
</div>
      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Marcelo Araya-Salas, Grace Smith-Vidaurre.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  


  
</body>
</html>
